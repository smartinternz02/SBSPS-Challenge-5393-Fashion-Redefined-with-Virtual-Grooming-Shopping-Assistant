{"cells": [{"metadata": {}, "cell_type": "code", "source": "from mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\n\nimport matplotlib.pyplot as plt # plotting\nimport matplotlib.image as mpimg\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os # accessing directory structure\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Convolution2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\n\n\n", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\ntest_datagen=ImageDataGenerator(rescale=1./255)\n", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_057b90874d074858851a6b72b9401168 = 'https://s3.us.cloud-object-storage.appdomain.cloud'\nelse:\n    endpoint_057b90874d074858851a6b72b9401168 = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n\nclient_057b90874d074858851a6b72b9401168 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='oDkAOEnFOplGq4Pd0ctBKWKpnkOkPXayNGFWtl3CJh9L',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url=endpoint_057b90874d074858851a6b72b9401168)\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_10 = client_057b90874d074858851a6b72b9401168.get_object(Bucket='fashionassistant-donotdelete-pr-mjgt9bn5i8dhxd', Key='ibmproj1.zip')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(streaming_body_10, \"__iter__\"): streaming_body_10.__iter__ = types.MethodType( __iter__, streaming_body_10 ) \n", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_10.read()),'r')\nfile_paths=unzip.namelist()\n#print(file_paths)\nfor path in file_paths:\n    unzip.extract(path) ", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 25, "outputs": [{"output_type": "execute_result", "execution_count": 25, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import os\nfilenames=os.listdir('/home/wsuser/work/ibmproj/train')", "execution_count": 26, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "x_train=train_datagen.flow_from_directory('/home/wsuser/work/ibmproj/train',target_size=(64,64),batch_size=32,class_mode=\"categorical\")\nx_test=test_datagen.flow_from_directory('/home/wsuser/work/ibmproj/test',target_size=(64,64),batch_size=32,class_mode=\"categorical\")", "execution_count": 27, "outputs": [{"output_type": "stream", "text": "Found 4108 images belonging to 7 classes.\nFound 2215 images belonging to 7 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "x_train.class_indices", "execution_count": 28, "outputs": [{"output_type": "execute_result", "execution_count": 28, "data": {"text/plain": "{'accessories': 0,\n 'bags': 1,\n 'footwear': 2,\n 'mens wear': 3,\n 'sunglasses': 4,\n 'watches': 5,\n 'womens wear': 6}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model=Sequential()", "execution_count": 29, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(MaxPooling2D(pool_size=(2,2)))", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(Convolution2D(64,(3,3),activation=\"relu\"))", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(MaxPooling2D(pool_size=(2,2)))", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(Convolution2D(128,(3,3),activation=\"relu\"))", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(MaxPooling2D(pool_size=(2,2)))", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(Flatten()) #input layer ", "execution_count": 36, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(Dense(units=7,kernel_initializer=\"random_uniform\",activation=\"relu\"))", "execution_count": 37, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.add(Dense(units=7,kernel_initializer=\"random_uniform\",activation=\"softmax\"))", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model.fit_generator(x_train,steps_per_epoch =128 ,epochs=50,validation_data=x_test,validation_steps=69)", "execution_count": 41, "outputs": [{"output_type": "stream", "text": "Epoch 1/50\n128/128 [==============================] - 184s 1s/step - loss: 0.5012 - accuracy: 0.8261 - val_loss: 0.5760 - val_accuracy: 0.7966\nEpoch 2/50\n128/128 [==============================] - 186s 1s/step - loss: 0.4688 - accuracy: 0.8449 - val_loss: 0.4798 - val_accuracy: 0.8229\nEpoch 3/50\n128/128 [==============================] - 186s 1s/step - loss: 0.4170 - accuracy: 0.8624 - val_loss: 0.4908 - val_accuracy: 0.8279\nEpoch 4/50\n128/128 [==============================] - 186s 1s/step - loss: 0.3808 - accuracy: 0.8685 - val_loss: 0.4338 - val_accuracy: 0.8424\nEpoch 5/50\n128/128 [==============================] - 185s 1s/step - loss: 0.3380 - accuracy: 0.8881 - val_loss: 0.4445 - val_accuracy: 0.8438\nEpoch 6/50\n128/128 [==============================] - 185s 1s/step - loss: 0.3213 - accuracy: 0.8913 - val_loss: 0.4598 - val_accuracy: 0.8519\nEpoch 7/50\n128/128 [==============================] - 186s 1s/step - loss: 0.2977 - accuracy: 0.9053 - val_loss: 0.4023 - val_accuracy: 0.8537\nEpoch 8/50\n128/128 [==============================] - 185s 1s/step - loss: 0.2874 - accuracy: 0.9019 - val_loss: 0.4531 - val_accuracy: 0.8637\nEpoch 9/50\n128/128 [==============================] - 186s 1s/step - loss: 0.2628 - accuracy: 0.9119 - val_loss: 0.4470 - val_accuracy: 0.8587\nEpoch 10/50\n128/128 [==============================] - 185s 1s/step - loss: 0.2498 - accuracy: 0.9181 - val_loss: 0.4071 - val_accuracy: 0.8696\nEpoch 11/50\n128/128 [==============================] - 186s 1s/step - loss: 0.2409 - accuracy: 0.9146 - val_loss: 0.4058 - val_accuracy: 0.8768\nEpoch 12/50\n128/128 [==============================] - 187s 1s/step - loss: 0.2335 - accuracy: 0.9171 - val_loss: 0.4058 - val_accuracy: 0.8718\nEpoch 13/50\n128/128 [==============================] - 186s 1s/step - loss: 0.2208 - accuracy: 0.9259 - val_loss: 0.4259 - val_accuracy: 0.8777\nEpoch 14/50\n128/128 [==============================] - 186s 1s/step - loss: 0.2141 - accuracy: 0.9303 - val_loss: 0.4103 - val_accuracy: 0.8759\nEpoch 15/50\n128/128 [==============================] - 185s 1s/step - loss: 0.2135 - accuracy: 0.9301 - val_loss: 0.5141 - val_accuracy: 0.8514\nEpoch 16/50\n128/128 [==============================] - 186s 1s/step - loss: 0.1897 - accuracy: 0.9384 - val_loss: 0.4832 - val_accuracy: 0.8732\nEpoch 17/50\n128/128 [==============================] - 186s 1s/step - loss: 0.1794 - accuracy: 0.9406 - val_loss: 0.4936 - val_accuracy: 0.8659\nEpoch 18/50\n128/128 [==============================] - 185s 1s/step - loss: 0.1743 - accuracy: 0.9448 - val_loss: 0.4953 - val_accuracy: 0.8709\nEpoch 19/50\n128/128 [==============================] - 185s 1s/step - loss: 0.1600 - accuracy: 0.9446 - val_loss: 0.4720 - val_accuracy: 0.8678\nEpoch 20/50\n128/128 [==============================] - 186s 1s/step - loss: 0.1575 - accuracy: 0.9436 - val_loss: 0.4446 - val_accuracy: 0.8764\nEpoch 21/50\n128/128 [==============================] - 185s 1s/step - loss: 0.1651 - accuracy: 0.9441 - val_loss: 0.4368 - val_accuracy: 0.8709\nEpoch 22/50\n128/128 [==============================] - 185s 1s/step - loss: 0.1518 - accuracy: 0.9490 - val_loss: 0.4665 - val_accuracy: 0.8709\nEpoch 23/50\n128/128 [==============================] - 186s 1s/step - loss: 0.1496 - accuracy: 0.9473 - val_loss: 0.4598 - val_accuracy: 0.8741\nEpoch 24/50\n128/128 [==============================] - 186s 1s/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.4827 - val_accuracy: 0.8777\nEpoch 25/50\n128/128 [==============================] - 184s 1s/step - loss: 0.1553 - accuracy: 0.9495 - val_loss: 0.4343 - val_accuracy: 0.8777\nEpoch 26/50\n128/128 [==============================] - 183s 1s/step - loss: 0.1327 - accuracy: 0.9558 - val_loss: 0.4670 - val_accuracy: 0.8890\nEpoch 27/50\n128/128 [==============================] - 183s 1s/step - loss: 0.1337 - accuracy: 0.9551 - val_loss: 0.4900 - val_accuracy: 0.8795\nEpoch 28/50\n128/128 [==============================] - 182s 1s/step - loss: 0.1284 - accuracy: 0.9553 - val_loss: 0.4964 - val_accuracy: 0.8723\nEpoch 29/50\n128/128 [==============================] - 181s 1s/step - loss: 0.1272 - accuracy: 0.9573 - val_loss: 0.4142 - val_accuracy: 0.8845\nEpoch 30/50\n128/128 [==============================] - 181s 1s/step - loss: 0.1214 - accuracy: 0.9603 - val_loss: 0.4376 - val_accuracy: 0.8886\nEpoch 31/50\n128/128 [==============================] - 181s 1s/step - loss: 0.1154 - accuracy: 0.9607 - val_loss: 0.4962 - val_accuracy: 0.8845\nEpoch 32/50\n128/128 [==============================] - 182s 1s/step - loss: 0.1093 - accuracy: 0.9632 - val_loss: 0.5155 - val_accuracy: 0.8804\nEpoch 33/50\n128/128 [==============================] - 182s 1s/step - loss: 0.1223 - accuracy: 0.9585 - val_loss: 0.5617 - val_accuracy: 0.8755\nEpoch 34/50\n128/128 [==============================] - 182s 1s/step - loss: 0.1026 - accuracy: 0.9642 - val_loss: 0.6004 - val_accuracy: 0.8827\nEpoch 35/50\n128/128 [==============================] - 183s 1s/step - loss: 0.0990 - accuracy: 0.9657 - val_loss: 0.4886 - val_accuracy: 0.8782\nEpoch 36/50\n128/128 [==============================] - 183s 1s/step - loss: 0.1046 - accuracy: 0.9652 - val_loss: 0.5588 - val_accuracy: 0.8773\nEpoch 37/50\n128/128 [==============================] - 183s 1s/step - loss: 0.1010 - accuracy: 0.9674 - val_loss: 0.4765 - val_accuracy: 0.8709\nEpoch 38/50\n128/128 [==============================] - 183s 1s/step - loss: 0.0903 - accuracy: 0.9691 - val_loss: 0.4722 - val_accuracy: 0.8909\nEpoch 39/50\n128/128 [==============================] - 182s 1s/step - loss: 0.0823 - accuracy: 0.9708 - val_loss: 0.5544 - val_accuracy: 0.8795\nEpoch 40/50\n128/128 [==============================] - 182s 1s/step - loss: 0.0941 - accuracy: 0.9696 - val_loss: 0.4901 - val_accuracy: 0.8954\nEpoch 41/50\n128/128 [==============================] - 182s 1s/step - loss: 0.1027 - accuracy: 0.9659 - val_loss: 0.5213 - val_accuracy: 0.8909\nEpoch 42/50\n128/128 [==============================] - 182s 1s/step - loss: 0.0894 - accuracy: 0.9696 - val_loss: 0.6486 - val_accuracy: 0.8709\nEpoch 43/50\n128/128 [==============================] - 180s 1s/step - loss: 0.0967 - accuracy: 0.9691 - val_loss: 0.6435 - val_accuracy: 0.8791\nEpoch 44/50\n128/128 [==============================] - 181s 1s/step - loss: 0.0865 - accuracy: 0.9698 - val_loss: 0.4703 - val_accuracy: 0.8877\nEpoch 45/50\n128/128 [==============================] - 181s 1s/step - loss: 0.0791 - accuracy: 0.9703 - val_loss: 0.6208 - val_accuracy: 0.8768\nEpoch 46/50\n128/128 [==============================] - 182s 1s/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 0.6686 - val_accuracy: 0.8800\nEpoch 47/50\n128/128 [==============================] - 186s 1s/step - loss: 0.0839 - accuracy: 0.9723 - val_loss: 0.4729 - val_accuracy: 0.8895\nEpoch 48/50\n128/128 [==============================] - 186s 1s/step - loss: 0.0949 - accuracy: 0.9701 - val_loss: 0.5581 - val_accuracy: 0.8863\nEpoch 49/50\n128/128 [==============================] - 186s 1s/step - loss: 0.0758 - accuracy: 0.9760 - val_loss: 0.5976 - val_accuracy: 0.8854\nEpoch 50/50\n128/128 [==============================] - 186s 1s/step - loss: 0.0814 - accuracy: 0.9713 - val_loss: 0.5851 - val_accuracy: 0.8854\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 41, "data": {"text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f12b8371490>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model.save(\"fashion.h5\")", "execution_count": 42, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!tar -zcvf image-classification-model_new.tgz fashion.h5", "execution_count": 43, "outputs": [{"output_type": "stream", "text": "fashion.h5\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "ls -1", "execution_count": 44, "outputs": [{"output_type": "stream", "text": "fashion.h5\r\n\u001b[0m\u001b[01;34mibmproj\u001b[0m/\r\nimage-classification-model_new.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client --upgrade", "execution_count": 45, "outputs": [{"output_type": "stream", "text": "Collecting watson-machine-learning-client\n  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 538 kB 27.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.26.6)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.25.1)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (4.59.0)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.2.4)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2021.5.30)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.17.46)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.7.0)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.3.6)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: botocore<1.21.0,>=1.20.46 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (1.20.88)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (2.8.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\nRequirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk->watson-machine-learning-client) (0.15.2)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (2.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (3.0.4)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (2021.1)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (1.19.2)\nInstalling collected packages: watson-machine-learning-client\nSuccessfully installed watson-machine-learning-client-1.0.391\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials={\n    \"url\":\"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\":\"pwNooTwaTrFqobYoOD4ITR71Xn5GP0ccE5kVbPuQ2vbj\"\n}\nclient =APIClient(wml_credentials)", "execution_count": 46, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client=APIClient(wml_credentials)", "execution_count": 47, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guide_from_space_name(client,space_name):\n    space=client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])\n", "execution_count": 48, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid=guide_from_space_name(client,'imageclassification')\nprint(\"Space UID = \"+ space_uid)", "execution_count": 49, "outputs": [{"output_type": "stream", "text": "Space UID = 8183ee11-bfbb-49c3-b32b-07d6c488c0ae\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 50, "outputs": [{"output_type": "execute_result", "execution_count": 50, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 51, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\nspark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\ntensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\nspss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\npytorch-onnx_1.2-py3.6         692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\ndo_12.9                        75a3a4b0-6aa0-41b3-a618-48b1f56332a6  base\nspark-mllib_2.3-scala_2.11     7963efe5-bbec-417e-92cf-0574e21b4e8d  base\nspark-mllib_2.4-py37           7abc992b-b685-532b-a122-a396a3cdbaab  base\ncaffe_1.0-py3.6                7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\npytorch-onnx_1.7-py3.7         812c6631-42b7-5613-982b-02098e6c909c  base\ncuda-py3.6                     82c79ece-4d12-40e6-8787-a7b9e0f62770  base\ntensorflow_1.15-py3.6-horovod  8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\nhybrid_0.1                     8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\npytorch-onnx_1.3-py3.7         8d5d8a87-a912-54cf-81ec-3914adaa988d  base\ncaffe-ibm_1.0-py3.6            8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\nspss-modeler_17.1              902d0051-84bd-4af6-ab6b-8f6aa6fdeabb  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid=client.software_specifications.get_uid_by_name('tensorflow_1.15-py3.6')\nsoftware_spec_uid", "execution_count": 52, "outputs": [{"output_type": "execute_result", "execution_count": 52, "data": {"text/plain": "'2b73a275-7cbf-420b-a912-eae7f436e0bc'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details=client.repository.store_model(model='image-classification-model_new.tgz',meta_props={\nclient.repository.ModelMetaNames.NAME:\"imageclassification\",\nclient.repository.ModelMetaNames.TYPE:\"keras_2.2.4\",\nclient.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid }\n                                           )\n\nmodel_id=client.repository.get_model_uid(model_details)\n", "execution_count": 53, "outputs": [{"output_type": "stream", "text": "Note: Warnings!! :  Model type keras_2.2.4 is deprecated. We recommend you use a supported model type. See Supported Frameworks https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": 54, "outputs": [{"output_type": "execute_result", "execution_count": 54, "data": {"text/plain": "'f0257b2a-c811-490f-8ce4-8177211925df'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.repository.download(model_id,'my_model.tar.gz')", "execution_count": 55, "outputs": [{"output_type": "stream", "text": "Successfully saved model content to file: 'my_model.tar.gz'\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 55, "data": {"text/plain": "'/home/wsuser/work/my_model.tar.gz'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing import image", "execution_count": 56, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model=load_model(\"fashion.h5\")", "execution_count": 57, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\nstreaming_body_18 = client_057b90874d074858851a6b72b9401168.get_object(Bucket='fashionassistant-donotdelete-pr-mjgt9bn5i8dhxd', Key='mens.zip')['Body']\n# add missing __iter__ method so pandas accepts body as file-like object\nif not hasattr(streaming_body_18, \"__iter__\"): streaming_body_18.__iter__ = types.MethodType( __iter__, streaming_body_18 ) \n", "execution_count": 114, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\nunzip=zipfile.ZipFile(BytesIO(streaming_body_18.read()),'r')\nfile_paths=unzip.namelist()\n#print(file_paths)\nfor path in file_paths:\n    unzip.extract(path) \n", "execution_count": 115, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "img=image.load_img(path,streaming_body_18,target_size=(64,64))", "execution_count": 116, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np\nx=image.img_to_array(img)\nx=np.expand_dims(x,axis=0)", "execution_count": 117, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred=model.predict_classes(x)", "execution_count": 118, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pred[0]", "execution_count": 119, "outputs": [{"output_type": "execute_result", "execution_count": 119, "data": {"text/plain": "3"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "index=[\"accessories\",\"bags\",\"footwear\",\"mens wear\",\"sunglasses\",\"watches\",\"womens wear\"]", "execution_count": 120, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "a=index[pred[0]]\nprint(a)", "execution_count": 121, "outputs": [{"output_type": "stream", "text": "mens wear\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}